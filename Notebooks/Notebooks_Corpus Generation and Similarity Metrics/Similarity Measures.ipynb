{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9068e4d6-d8df-4a88-8700-c3ed0111360e",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a58aeb-7a2a-4a51-90b3-f6883f5a6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import spatial\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, NearestNeighbors\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c663b0-4fe5-49a0-b0ac-0d759fc51818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_list(X, eval_distance_metric='cosine'):\n",
    "    return spatial.distance.pdist(X, eval_distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4751d74a-589f-4260-84b3-1a8025a25ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_int_mapping(strings):\n",
    "    # Create a dictionary to store string to integer mapping\n",
    "    string_to_int = {}\n",
    "    int_sequence = []\n",
    "\n",
    "    # Assign a unique integer to each unique string\n",
    "    for string in strings:\n",
    "        if string not in string_to_int:\n",
    "            string_to_int[string] = len(string_to_int)  # Assign the next available integer\n",
    "        # Append the corresponding integer to the sequence\n",
    "        int_sequence.append(string_to_int[string])\n",
    "\n",
    "    return int_sequence, string_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3d6815-7e11-49a2-a20d-39bc91bafbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_matrix(X_scatter):\n",
    "    # Compute pairwise Euclidean distances\n",
    "    pairwise_distances = pdist(X_scatter, metric='euclidean')\n",
    "    \n",
    "    # Convert to square matrix form\n",
    "    distance_matrix = squareform(pairwise_distances)\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c2cb45-902f-4078-b5a6-38ffdc89f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_common_elements(list1, list2):\n",
    "    count_list1 = {}\n",
    "    count_list2 = {}\n",
    "    \n",
    "    for element in list1:\n",
    "        count_list1[element] = count_list1.get(element, 0) + 1\n",
    "    \n",
    "    for element in list2:\n",
    "        count_list2[element] = count_list2.get(element, 0) + 1\n",
    "        \n",
    "    shared_elements_count = 0\n",
    "    \n",
    "    for element, count in count_list1.items():\n",
    "        shared_elements_count += min(count, count_list2.get(element, 0))\n",
    "    return shared_elements_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154bf2a3-19b0-489f-a55f-9d0a4143ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_scatter, k=7, distance_function=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Compute the k-nearest neighbors of the points\n",
    "    If the distance function is euclidean, the computation relies on faiss-cpu.\n",
    "    Otherwise, the computation is done based on scikit-learn KD Tree algorithm\n",
    "    You can use any distance function supported by scikit-learn KD Tree or specify a callable function\n",
    "    INPUT:\n",
    "        ndarray: points: list of points\n",
    "\t\tint: k: number of nearest neighbors to compute\n",
    "\t\tstr or callable: distance_function: distance function to use\n",
    "    OUTPUT:\n",
    "\t\tndarray: knn_indices: k-nearest neighbors of each point \n",
    "\t\"\"\"\n",
    "    \n",
    "\t\n",
    "\t## make c-contiguous\n",
    "    points = np.ascontiguousarray(X_scatter, dtype=np.float32)\n",
    "\n",
    "    if distance_function == \"euclidean\":\n",
    "        index = faiss.IndexFlatL2(points.shape[1])\n",
    "        index.add(points)\n",
    "        knn_indices = index.search(points, k+1)[1][:, 1:]\n",
    "\t\n",
    "    return knn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf8ec3b-93c2-48fd-8b36-fad2ba5a22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_with_ranking(points, k, distance_matrix):\n",
    "  knn_indices = np.empty((points.shape[0], k), dtype=np.int32)\n",
    "  ranking = np.empty((points.shape[0], points.shape[0]), dtype=np.int32)\n",
    "  \n",
    "  for i in range(points.shape[0]):\n",
    "    distance_to_i = distance_matrix[i]\n",
    "    sorted_indices = np.argsort(distance_to_i)\n",
    "    knn_indices[i] = sorted_indices[1:k+1]\n",
    "    ranking[i] = np.argsort(sorted_indices)\n",
    "  \n",
    "  return knn_indices, ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc8d23-1e02-4678-a52d-a701dc02f515",
   "metadata": {},
   "source": [
    "### Global Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e71abd-2883-46e5-b87e-10f779dd304e",
   "metadata": {},
   "source": [
    "Our analysis of the global similarity between two scatter plots relies on the following four metrics <br>\n",
    "1. Pearson's correlation coefficient\n",
    "2. Spearman's rank correlation coefficient\n",
    "3. Cluster Ordering, and the\n",
    "4. Rotation derived from Procrustes analysis\n",
    "\n",
    "We ignore metrics that are not normalized, e.g., Stress, Kullback-Leiber Divergence, Distance-to-Measure, or the Topographic Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735e2166-adad-477e-91ac-5ff999d6d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's correlation coefficient\n",
    "def metric_spearman_correlation(D_scatter1, D_scatter2):\n",
    "    return stats.spearmanr(D_scatter1, D_scatter2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce85677-a703-4fbb-9f7e-60d7f05d6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's rank correlation coefficient\n",
    "def metric_pearson_correlation(D_scatter1, D_scatter2):\n",
    "    return stats.pearsonr(D_scatter1, D_scatter2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e78965-bb55-4c43-8c96-fc5b7ee4fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Ordering\n",
    "def metric_cluster_ordering(X_scatter1, X_scatter2, y):\n",
    "    #clf_scatter1 = NearestCentroid().fit(X = df_scatter1, y = y)\n",
    "    #clf_scatter2 = NearestCentroid().fit(X = df_scatter2, y = y)\n",
    "    clf_scatter1 = NearestCentroid().fit(X = X_scatter1, y = y)\n",
    "    clf_scatter2 = NearestCentroid().fit(X = X_scatter2, y = y)\n",
    "    \n",
    "    D_scatter1 = compute_distance_list(clf_scatter1.centroids_, 'euclidean')\n",
    "    D_scatter2 = compute_distance_list(clf_scatter2.centroids_, 'euclidean')\n",
    "    \n",
    "    return metric_spearman_correlation(D_scatter1, D_scatter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4389cd-0665-40fe-ba57-6016097c5660",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scatter1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metric_cluster_ordering(X_scatter1, X_scatter2, Y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scatter1' is not defined"
     ]
    }
   ],
   "source": [
    "metric_cluster_ordering(X_scatter1, X_scatter2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b52a5-78ee-4d09-9fe3-a8826f7ab9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation derived from Procrustes analysis\n",
    "def center(X_scatter):\n",
    "    n,m = X_scatter.shape\n",
    "    x_mean = sum(X_scatter[:,0].tolist())/n\n",
    "    y_mean = sum(X_scatter[:,1].tolist())/n\n",
    "    return X_scatter - [x_mean, y_mean]\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/18925181/procrustes-analysis-with-numpy\n",
    "def procrustes_manual(X, Y, scaling=True, reflection='best'):\n",
    "    \"\"\"\n",
    "    A port of MATLAB's `procrustes` function to Numpy.\n",
    "\n",
    "    Procrustes analysis determines a linear transformation (translation,\n",
    "    reflection, orthogonal rotation and scaling) of the points in Y to best\n",
    "    conform them to the points in matrix X, using the sum of squared errors\n",
    "    as the goodness of fit criterion.\n",
    "\n",
    "        d, Z, [tform] = procrustes(X, Y)\n",
    "\n",
    "    Inputs:\n",
    "    ------------\n",
    "    X, Y    \n",
    "        matrices of target and input coordinates. they must have equal\n",
    "        numbers of  points (rows), but Y may have fewer dimensions\n",
    "        (columns) than X.\n",
    "\n",
    "    scaling \n",
    "        if False, the scaling component of the transformation is forced\n",
    "        to 1\n",
    "\n",
    "    reflection\n",
    "        if 'best' (default), the transformation solution may or may not\n",
    "        include a reflection component, depending on which fits the data\n",
    "        best. setting reflection to True or False forces a solution with\n",
    "        reflection or no reflection respectively.\n",
    "\n",
    "    Outputs\n",
    "    ------------\n",
    "    d       \n",
    "        the residual sum of squared errors, normalized according to a\n",
    "        measure of the scale of X, ((X - X.mean(0))**2).sum()\n",
    "\n",
    "    Z\n",
    "        the matrix of transformed Y-values\n",
    "\n",
    "    tform   \n",
    "        a dict specifying the rotation, translation and scaling that\n",
    "        maps X --> Y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n,m = X.shape\n",
    "    ny,my = Y.shape\n",
    "\n",
    "    muX = X.mean(0)\n",
    "    muY = Y.mean(0)\n",
    "\n",
    "    X0 = X - muX\n",
    "    Y0 = Y - muY\n",
    "\n",
    "    ssX = (X0**2.).sum()\n",
    "    ssY = (Y0**2.).sum()\n",
    "\n",
    "    # centred Frobenius norm\n",
    "    normX = np.sqrt(ssX)\n",
    "    normY = np.sqrt(ssY)\n",
    "\n",
    "    # scale to equal (unit) norm\n",
    "    X0 /= normX\n",
    "    Y0 /= normY\n",
    "\n",
    "    if my < m:\n",
    "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
    "\n",
    "    # optimum rotation matrix of Y\n",
    "    A = np.dot(X0.T, Y0)\n",
    "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    T = np.dot(V, U.T)\n",
    "\n",
    "    if reflection != 'best':\n",
    "\n",
    "        # does the current solution use a reflection?\n",
    "        have_reflection = np.linalg.det(T) < 0\n",
    "\n",
    "        # if that's not what was specified, force another reflection\n",
    "        if reflection != have_reflection:\n",
    "            V[:,-1] *= -1\n",
    "            s[-1] *= -1\n",
    "            T = np.dot(V, U.T)\n",
    "\n",
    "    traceTA = s.sum()\n",
    "\n",
    "    if scaling:\n",
    "\n",
    "        # optimum scaling of Y\n",
    "        b = traceTA * normX / normY\n",
    "\n",
    "        # standarised distance between X and b*Y*T + c\n",
    "        d = 1 - traceTA**2\n",
    "\n",
    "        # transformed coords\n",
    "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
    "\n",
    "    else:\n",
    "        b = 1\n",
    "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
    "        Z = normY*np.dot(Y0, T) + muX\n",
    "\n",
    "    # transformation matrix\n",
    "    if my < m:\n",
    "        T = T[:my,:]\n",
    "    c = muX - b*np.dot(muY, T)\n",
    "    \n",
    "    #transformation values \n",
    "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
    "   \n",
    "    return d, Z, tform\n",
    "\n",
    "def get_rotation_angle(rotation_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the rotation angle from a 2x2 rotation matrix.\n",
    "    \"\"\"\n",
    "    angle_rad = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262ba91-7040-4839-8677-59bbfdc276e8",
   "metadata": {},
   "source": [
    "### Local Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7363e85a-1aab-4935-a3e8-f57d67a3de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trustworthiness\n",
    "def metric_trustworthiness(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7):\n",
    "    #D_scatter1 = spatial.distance.squareform(D_scatter1)\n",
    "    #D_scatter2 = spatial.distance.squareform(D_scatter2)\n",
    "    \n",
    "    n = X_scatter1.shape[0]\n",
    "    \n",
    "    nn_scatter1 = D_scatter1_square.argsort()\n",
    "    nn_scatter2 = D_scatter2_square.argsort()\n",
    "    \n",
    "    knn_scatter1 = nn_scatter1[:, :k + 1][:, 1:]\n",
    "    knn_scatter2 = nn_scatter2[:, :k + 1][:, 1:]\n",
    "    \n",
    "    sum_i = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        U = np.setdiff1d(knn_scatter2[i], knn_scatter1[i])\n",
    "        \n",
    "        sum_j = 0\n",
    "        for j in range(U.shape[0]):\n",
    "            sum_j += np.where(nn_scatter1[i] == U[j])[0] - k\n",
    "        \n",
    "        sum_i += sum_j\n",
    "        \n",
    "    return float((1 - (2 / (n * k * (2 * n - 3 * k -1)) * sum_i)).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221b32f0-b435-4896-8edd-4ee0ae38c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuity\n",
    "def metric_continuity(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7):\n",
    "    n = X_scatter1.shape[0]\n",
    "\n",
    "    nn_scatter1 = D_scatter1_square.argsort()\n",
    "    nn_scatter2 = D_scatter2_square.argsort()\n",
    "\n",
    "    knn_scatter1 = nn_scatter1[:, :k + 1][:, 1:]\n",
    "    knn_scatter2 = nn_scatter2[:, :k + 1][:, 1:]\n",
    "\n",
    "    sum_i = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        V = np.setdiff1d(knn_scatter1[i], knn_scatter2[i])\n",
    "\n",
    "        sum_j = 0\n",
    "        for j in range(V.shape[0]):\n",
    "            sum_j += np.where(nn_scatter2[i] == V[j])[0] - k\n",
    "\n",
    "        sum_i += sum_j\n",
    "\n",
    "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d46107-8d67-4c37-8123-4575abe35668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Preservation\n",
    "def metric_label_preservation(X_scatter1, X_scatter2, y, k=7):\n",
    "    #arr_scatter1 = scatter1.values\n",
    "    #arr_scatter2 = scatter2.values\n",
    "    label_preservation = 0\n",
    "    \n",
    "    nbrs_scatter1 = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X_scatter1)\n",
    "    nbrs_scatter2 = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X_scatter2)\n",
    "    \n",
    "    for i in range(X_scatter1.shape[0]):\n",
    "        distances_scatter1, indices_scatter1 = nbrs_scatter1.kneighbors(X_scatter1[i].reshape(1, -1))\n",
    "        distances_scatter2, indices_scatter2 = nbrs_scatter2.kneighbors(X_scatter2[i].reshape(1, -1))\n",
    "        \n",
    "        indices_scatter1_list = indices_scatter1[0].tolist()\n",
    "        indices_scatter2_list = indices_scatter2[0].tolist()\n",
    "        \n",
    "        labels_scatter1 = [y[index] for index in indices_scatter1_list]\n",
    "        labels_scatter2 = [y[index] for index in indices_scatter2_list]\n",
    "        \n",
    "        label_preservation_pointwise = (count_common_elements(labels_scatter1, labels_scatter2) - 1)/7\n",
    "        label_preservation += label_preservation_pointwise\n",
    "    \n",
    "    return label_preservation/X_scatter1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62de9b8b-e5dd-4eef-8c40-6945dea87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Continuity Meta-Criterion (Jeon Hong)\n",
    "def metric_local_continuity(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7):\n",
    "    nn_scatter1 = D_scatter1_square.argsort()\n",
    "    nn_scatter2 = D_scatter2_square.argsort()\n",
    "    \n",
    "    knn_scatter1 = nn_scatter1[:, :k + 1][:, 1:]\n",
    "    knn_scatter2 = nn_scatter2[:, :k + 1][:, 1:]\n",
    "\n",
    "    point_num = X_scatter1.shape[0]\n",
    "    local_distortion_list = []\n",
    "\n",
    "    for i in range(point_num):\n",
    "        local_distortion_list.append(np.intersect1d(knn_scatter1[i], knn_scatter2[i]).shape[0] -((k*k)/(point_num - 1)))\n",
    "\n",
    "    local_distortion_list = np.array(local_distortion_list)\n",
    "    local_distortion_list = local_distortion_list / k \n",
    "  \n",
    "    average_distortion = np.mean(local_distortion_list)\n",
    "    return average_distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f472c5b-5334-4579-877b-90aaba1f08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_mrre_help(base_ranking,target_ranking, target_knn_indices, k=7):\n",
    "\tlocal_distortion_list = []\n",
    "\tpoints_num = target_knn_indices.shape[0]\n",
    "\tfor i in range(points_num):\n",
    "\t\tbase_rank_arr   = base_ranking[i][target_knn_indices[i]]\n",
    "\t\ttarget_rank_arr = target_ranking[i][target_knn_indices[i]]\n",
    "\t\tlocal_distortion_list.append(np.sum(np.abs(base_rank_arr - target_rank_arr) / target_rank_arr))\n",
    "\t\n",
    "\tc = sum([abs(points_num - 2 * i + 1) / i for i in range(1, k + 1)])\n",
    "\tlocal_distortion_list = np.array(local_distortion_list)\n",
    "\tlocal_distortion_list = 1 - local_distortion_list / c\n",
    "\n",
    "\taverage_distortion = np.mean(local_distortion_list)\n",
    "\n",
    "\treturn average_distortion\n",
    "\n",
    "\n",
    "def metric_mrre(X_scatter1, X_scatter2,D_scatter1_square, D_scatter2_square, k=7):\n",
    "\tscatter1_knn_indices, scatter1_ranking = knn_with_ranking(X_scatter1, k, D_scatter1_square)\n",
    "\tscatter2_knn_indices, scatter2_ranking = knn_with_ranking(X_scatter2, k, D_scatter2_square)\n",
    "\t\n",
    "\n",
    "\tmrre_false = metric_mrre_help(scatter1_ranking, scatter2_ranking, scatter2_knn_indices, k)\n",
    "\tmrre_missing = metric_mrre_help(scatter2_ranking, scatter1_ranking, scatter1_knn_indices, k)\n",
    "\n",
    "\treturn {\n",
    "\t\t\"mrre_false\": mrre_false,\n",
    "\t\t\"mrre_missing\": mrre_missing,\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad97ab-87d0-49cc-879e-742a86fba9b5",
   "metadata": {},
   "source": [
    "### Cluster-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6577a442-d5db-49be-b6b8-612a5f02fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Consistency\n",
    "def single_metric_distance_consistency(X_scatter, y):\n",
    "    clf = NearestCentroid()\n",
    "    clf.fit(X=X_scatter, y=y)\n",
    "    nearest_centroids = clf.predict(X=X_scatter)\n",
    "    num_same_label = sum([1 if y[i] == nearest_centroids[i] else 0 for i in range(len(y))])\n",
    "    return num_same_label / len(y)\n",
    "\n",
    "def metric_distance_consistency(X_scatter1, X_scatter2, y):\n",
    "    return abs(single_metric_distance_consistency(X_scatter1, y) - single_metric_distance_consistency(X_scatter2, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17428457-a3c7-4ace-8b81-cd2771acd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Coefficient\n",
    "def single_metric_silhouette_coefficient(X_scatter, y):\n",
    "    return silhouette_score(X_scatter, y, metric='euclidean')\n",
    "\n",
    "def metric_silhouette_coefficient(X_scatter1, X_scatter2, y):\n",
    "    return abs(silhouette_score(X_scatter1, y, metric='euclidean') - silhouette_score(X_scatter2, y, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26eff405-2d42-49e8-bfb9-524e39b2399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calinski-Harabasz-Score\n",
    "def single_metric_calinski_harabasz_score(X_scatter, y):\n",
    "    return calinski_harabasz_score(X_scatter, y)\n",
    "\n",
    "def metric_calinski_harabasz_score(X_scatter1, X_scatter2, y):\n",
    "    return abs(calinski_harabasz_score(X_scatter1, y) - calinski_harabasz_score(X_scatter2, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a93d1f85-1e6f-4488-9b9f-35c09d411a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Davies-Boulding-Index\n",
    "def single_metric_davies_bouldin_score(X_scatter, y):\n",
    "    return davies_bouldin_score(X_scatter, y)\n",
    "\n",
    "def metric_davies_bouldin_score(X_scatter1, X_scatter2, y):\n",
    "    return abs(davies_bouldin_score(X_scatter1, y) - davies_bouldin_score(X_scatter2, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06902099-c383-44a2-9dfa-c82ac5d30b52",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12432012-53f4-40f1-bf24-078a8af0ceb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/results1_7Categories.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load first scatter plot\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_scatter1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/results1_7Categories.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# load second scatter plot\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_scatter2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/results2_7Categories.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/results1_7Categories.csv'"
     ]
    }
   ],
   "source": [
    "# load first scatter plot\n",
    "df_scatter1 = pd.read_csv(\"results/results1_7Categories.csv\")\n",
    "\n",
    "# load second scatter plot\n",
    "df_scatter2 = pd.read_csv(\"results/results2_7Categories.csv\")\n",
    "Y,_ = string_to_int_mapping(df_scatter2['labels'].tolist()) # both scatter plots have the same labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b640b6-1516-456b-aaf4-ba553d8b8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Tims Label Preservation\n",
    "# load first scatter plot\n",
    "df_scatter1 = pd.read_csv(\"D:/result/20_newsgroups/umap_20_newsgroups_nmf_tfidf_n_topics_20_5_0.8_cosine_1.0_1.0_1_1.0_5_58aaa17c4ffbd81_6377d5b9c5fe1a5.npy\")\n",
    "# umap_20_newsgroups_nmf_tfidf_n_topics_20_5_0.8_cosine_1.0_1.0_1_1.0_5_58aaa17c4ffbd81_6377d5b9c5fe1a5.npy\n",
    "\n",
    "# load second scatter plot\n",
    "df_scatter2 = pd.read_csv(\"results/results2_7Categories.csv\")\n",
    "Y,_ = string_to_int_mapping(df_scatter2['labels'].tolist()) # both scatter plots have the same labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d6755-24a1-44b3-8064-f0a913790f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots arranged horizontally\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# First scatter plot\n",
    "ax1.scatter(\n",
    "    x=df_scatter1['x'].tolist(), \n",
    "    y=df_scatter1['y'].tolist(), \n",
    "    c=Y, \n",
    "    cmap=plt.cm.get_cmap('Paired'), \n",
    "    alpha=1.0)\n",
    "ax1.set_title('Scatter Plot 1')\n",
    "\n",
    "# Second scatter plot\n",
    "ax2.scatter(\n",
    "    x=df_scatter2['x'].tolist(), \n",
    "    y=df_scatter2['y'].tolist(), \n",
    "    c=Y, \n",
    "    cmap=plt.cm.get_cmap('Paired'), \n",
    "    alpha=1.0)\n",
    "ax2.set_title('Scatter Plot 2')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb6429-35bb-4740-b203-4470041dade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scatter1 = df_scatter1[['x','y']].values\n",
    "X_scatter2 = df_scatter2[['x','y']].values\n",
    "\n",
    "D_scatter1 = compute_distance_list(X_scatter1, eval_distance_metric='euclidean')\n",
    "D_scatter2 = compute_distance_list(X_scatter2, eval_distance_metric='euclidean')\n",
    "\n",
    "D_scatter1_square = euclidean_distance_matrix(X_scatter1)\n",
    "D_scatter2_square = euclidean_distance_matrix(X_scatter2)\n",
    "\n",
    "Y,_ = string_to_int_mapping(df_scatter1['labels'].tolist())\n",
    "\n",
    "# Global measures\n",
    "print(\"GLOBAL MEASURES\")\n",
    "print(\"Spearman Correlation: \" + str(metric_spearman_correlation(D_scatter1, D_scatter2)))\n",
    "print(\"Pearson Correlation: \" + str(metric_pearson_correlation(D_scatter1, D_scatter2)))\n",
    "print(\"Cluster Ordering: \" + str(metric_cluster_ordering(X_scatter1, X_scatter2, Y)))\n",
    "d,Z,tform = procrustes_manual(center(X_scatter1), center(X_scatter2), reflection=\"False\")\n",
    "print(\"Rotation: \" + str(get_rotation_angle(tform[\"rotation\"])))\n",
    "print(\"\")\n",
    "print(\"CLUSTER-LEVEL MEASURES\")\n",
    "print(\"Distance Consistency: \" + str(metric_distance_consistency(X_scatter1, X_scatter2, Y)))\n",
    "print(\"Silhouette Coefficient: \" + str(metric_silhouette_coefficient(X_scatter1, X_scatter2, Y)))\n",
    "# print(\"Calinski Harabasz Score: \" + str(metric_calinski_harabasz_score(X_scatter1, X_scatter2, Y))) # does not have a predefined value range\n",
    "# print(\"Davies-Bouldin Score: \" + str(metric_davies_bouldin_score(X_scatter1, X_scatter2, Y))) # does not have a predefined value range\n",
    "print(\"\")\n",
    "print(\"LOCAL MEASURES\")\n",
    "print(\"Trustworthiness: \" + str(metric_trustworthiness(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7)))\n",
    "print(\"Continuity: \" + str(metric_continuity(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7)))\n",
    "print(\"Label Preservation: \" + str(metric_label_preservation(X_scatter1, X_scatter2, Y, k=7)))\n",
    "print(\"Local Continuity: \" + str(metric_local_continuity(X_scatter1, X_scatter2, D_scatter1_square, D_scatter2_square, k=7)))\n",
    "print(\"MRRE missing: \" + str(metric_mrre(X_scatter1, X_scatter2,D_scatter1_square, D_scatter2_square, k=7)['mrre_missing']))\n",
    "print(\"MRRE false: \" + str(metric_mrre(X_scatter1, X_scatter2,D_scatter1_square, D_scatter2_square, k=7)['mrre_false']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daee369-69bb-42ad-b543-5c8bd8e93bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
